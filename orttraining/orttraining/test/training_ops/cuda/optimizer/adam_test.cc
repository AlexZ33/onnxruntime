// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

#include "gtest/gtest.h"

#include "test/providers/provider_test_utils.h"

namespace onnxruntime {
namespace test {

namespace {

struct TensorInfo {
  TensorInfo(VectorInt64 shapes, std::vector<float> values) {
    shapes_ = shapes;
    fp32_values_ = values;

    size_t total_size = 1;
    for (size_t i = 0; i < shapes_.size(); ++i) {
      total_size *= shapes_[i];
    }

    EXPECT_TRUE(fp32_values_.size() == total_size) << "Number of elements mismtach betwen shapes and values."
                                                   << "fp32_values_.size():" << fp32_values_.size()
                                                   << ", total_size: " << total_size;
  }

  template <typename OutT>
  std::vector<OutT> Values() const {
    if (std::is_same<OutT, MLFloat16>::value) {
      std::vector<OutT> fp16_values;
      fp16_values.reserve(fp32_values_.size());
      ConvertFloatToMLFloat16(fp32_values_.data(), reinterpret_cast<onnxruntime::MLFloat16*>(fp16_values.data()), fp32_values_.size());
      return fp16_values;
    } else if (std::is_same<OutT, float>::value) {
      return fp32_values_;
    } else {
      ORT_THROW("Not supported data type.");
    }
  }

  VectorInt64 Shapes() const {
    return shapes_;
  }

  VectorInt64 shapes_;
  std::vector<float> fp32_values_;
};

template <typename T>
struct AdamTestInputOutput {
  AdamTestInputOutput(
      float lr,
      int64_t step,
      const std::vector<TensorInfo>& weight_tensor_infos,
      const std::vector<TensorInfo>& gradient_tensor_infos,
      const std::vector<TensorInfo>& momentum_1_tensor_infos,
      const std::vector<TensorInfo>& momentum_2_tensor_infos,
      const std::vector<TensorInfo>& updated_weight_tensor_infos,
      const std::vector<TensorInfo>& updated_momentum_1_tensor_infos,
      const std::vector<TensorInfo>& updated_momentum_2_tensor_infos) {
    lr_vector.push_back(lr);
    step_vector.push_back(step);

    // Input Sequence tensors.

    for (const TensorInfo& ti : weight_tensor_infos) {
      weight_seq_tensors_.AddTensor(ti.Shapes(), ti.Values<T>());
    }

    for (const TensorInfo& ti : gradient_tensor_infos) {
      gradient_seq_tensors_.AddTensor(ti.Shapes(), ti.Values<T>());
    }

    for (const TensorInfo& ti : momentum_1_tensor_infos) {
      momentum_1_seq_tensors_.AddTensor(ti.Shapes(), ti.Values<T>());
    }

    for (const TensorInfo& ti : momentum_2_tensor_infos) {
      momentum_2_seq_tensors_.AddTensor(ti.Shapes(), ti.Values<T>());
    }

    // Update sequence tensors.

    for (const TensorInfo& ti : updated_weight_tensor_infos) {
      updated_weight_seq_tensors_.AddTensor(ti.Shapes(), ti.Values<T>());
    }

    for (const TensorInfo& ti : updated_momentum_1_tensor_infos) {
      updated_momentum_1_seq_tensors_.AddTensor(ti.Shapes(), ti.Values<T>());
    }

    for (const TensorInfo& ti : updated_momentum_2_tensor_infos) {
      updated_momentum_2_seq_tensors_.AddTensor(ti.Shapes(), ti.Values<T>());
    }
  }

  SeqTensors<T>& WeightSeq() {
    return weight_seq_tensors_;
  }

  SeqTensors<T>& GradientSeq() {
    return gradient_seq_tensors_;
  }

  SeqTensors<T>& Momentum_1_Seq() {
    return momentum_1_seq_tensors_;
  }

  SeqTensors<T>& Momentum_2_Seq() {
    return momentum_2_seq_tensors_;
  }

  SeqTensors<T>& UpdatedWeightSeq() {
    return updated_weight_seq_tensors_;
  }

  SeqTensors<T>& UpdatedMomentum_1_Seq() {
    return updated_momentum_1_seq_tensors_;
  }

  SeqTensors<T>& UpdatedMomentum_2_Seq() {
    return updated_momentum_2_seq_tensors_;
  }

  std::vector<float> lr_vector;
  std::vector<int64_t> step_vector;

 private:
  SeqTensors<T> weight_seq_tensors_;
  SeqTensors<T> gradient_seq_tensors_;
  SeqTensors<T> momentum_1_seq_tensors_;
  SeqTensors<T> momentum_2_seq_tensors_;

  SeqTensors<T> updated_weight_seq_tensors_;
  SeqTensors<T> updated_momentum_1_seq_tensors_;
  SeqTensors<T> updated_momentum_2_seq_tensors_;
};

TEST(AdamTest, TorchAdamSingleWeightTest_Loop10Steps) {
  size_t total_step = 10;
  float lr = 1e-03;

  // 11 steps of weight values before applying optimization.
  std::vector<std::vector<float>> weights_per_step{
      {-0.18330414593219757, 0.6739549040794373, 0.31170889735221863, 0.42830976843833923, -0.3957911729812622,
       0.07424858212471008},
      {-0.1823023110628128, 0.6729481816291809, 0.31270575523376465, 0.4273054897785187, -0.3947872221469879,
       0.07324783504009247},
      {-0.1813177615404129, 0.6725299954414368, 0.31352442502975464, 0.4267500042915344, -0.39517560601234436,
       0.07235248386859894},
      {-0.18059654533863068, 0.6721751093864441, 0.3133564889431, 0.4261542558670044, -0.3952518701553345,
       0.07177812606096268},
      {-0.1797766387462616, 0.6717073917388916, 0.31389161944389343, 0.42545586824417114, -0.3956265449523926,
       0.0718231126666069},
      {-0.1797962337732315, 0.671058714389801, 0.31389155983924866, 0.42466312646865845, -0.3952196538448334,
       0.07233689725399017},
      {-0.179893359541893, 0.6702919602394104, 0.3141656517982483, 0.4244508147239685, -0.3947013318538666,
       0.07293851673603058},
      {-0.17997200787067413, 0.6695550084114075, 0.3144531548023224, 0.42422598600387573, -0.3940390944480896,
       0.07336583733558655},
      {-0.17965379357337952, 0.6687510013580322, 0.3146941661834717, 0.4239514470100403, -0.39327237010002136,
       0.07322362810373306},
      {-0.17922040820121765, 0.6680363416671753, 0.31512853503227234, 0.4236794114112854, -0.3924334645271301,
       0.07309211790561676},
      {-0.17886576056480408, 0.6672791242599487, 0.3152349591255188, 0.42340385913848877, -0.39180418848991394,
       0.07277242839336395},
  };

  // 10 steps of gradient values used to apply optimization.
  std::vector<std::vector<float>> gradients_per_step{
      {-0.18660534918308258, 1.0501877069473267, -0.06538727134466171, 0.7892400622367859, -0.06989894062280655,
       0.08311288058757782},
      {-0.14019422233104706, -0.33581918478012085, -0.015272594057023525, -0.11933345347642899, 0.15028853714466095,
       0.3035297095775604},
      {0.014209908433258533, 0.05260481685400009, 0.09717129915952682, 0.23888230323791504, -0.05665421858429909,
       -0.053932324051856995},
      {-0.31329306960105896, 0.38529160618782043, -0.5335826277732849, 0.41899508237838745, 0.11755916476249695,
       -0.2919110357761383},
      {0.5206083655357361, 0.9029364585876465, 0.4515741765499115, 1.2402161359786987, -0.5781408548355103,
       -0.9771140217781067},
      {0.10178368538618088, 1.272549033164978, -0.43885383009910583, -1.229077935218811, -0.24205324053764343,
       -0.4146330654621124},
      {-0.007725818548351526, 0.2862418293952942, -0.08212745189666748, 0.15442971885204315, -0.46201223134994507,
       0.2059977948665619},
      {-0.7134706377983093, 0.9803712964057922, 0.02016977034509182, 0.31701749563217163, -0.6400585174560547,
       1.4056847095489502},
      {-0.3544383645057678, 0.0006996551528573036, -0.5025327205657959, 0.11614283919334412, -0.7705468535423279,
       0.019379474222660065},
      {0.06727457791566849, 0.7126177549362183, 0.5345063805580139, 0.13658584654331207, 0.2790890336036682,
       0.8989311456680298},
  };

  // 11 steps of momentum1 values before applying optimization.
  std::vector<std::vector<float>> momentums_1_per_step{
      {0.0, 0.0, 0.0, 0.0, 0.0, 0.0},
      {-0.018660536035895348, 0.10501877218484879, -0.006538727320730686, 0.07892400771379471, -0.0069898939691483974,
       0.008311288431286812},
      {-0.030813904479146004, 0.06093497574329376, -0.007412114180624485, 0.0590982623398304, 0.008737949654459953,
       0.03783313184976578},
      {-0.026311522349715233, 0.060101959854364395, 0.0030462276190519333, 0.07707666605710983, 0.0021987329237163067,
       0.02865658327937126},
      {-0.05500967800617218, 0.09262092411518097, -0.050616659224033356, 0.11126850545406342, 0.01373477652668953,
       -0.0034001797903329134},
      {0.002552127931267023, 0.17365248501300812, -0.00039757348713465035, 0.2241632640361786, -0.0454527884721756,
       -0.10077156871557236},
      {0.012475283816456795, 0.2835421562194824, -0.04424320161342621, 0.07883913069963455, -0.06511283665895462,
       -0.13215771317481995},
      {0.010455173440277576, 0.28381210565567017, -0.04803162440657616, 0.08639819175004959, -0.10480277240276337,
       -0.0983421579003334},
      {-0.06193741038441658, 0.35346800088882446, -0.041211485862731934, 0.10946012288331985, -0.1583283543586731,
       0.052060529589653015},
      {-0.0911875069141388, 0.31819117069244385, -0.08734361082315445, 0.11012839525938034, -0.21955019235610962,
       0.04879242181777954},
      {-0.07534129917621613, 0.3576337993144989, -0.025158612057566643, 0.11277413368225098, -0.16968625783920288,
       0.1338062882423401},
  };

  // 11 steps of momentum2 values before applying optimization.
  std::vector<std::vector<float>> momentums_2_per_step{
      {0.0, 0.0, 0.0, 0.0, 0.0, 0.0},
      {3.4821558074327186e-05, 0.001102894195355475, 4.275495484762359e-06, 0.0006228999118320644, 4.885862381343031e-06,
       6.90775095790741e-06},
      {5.444115595309995e-05, 0.0012145658256486058, 4.504472144617466e-06, 0.0006365174776874483, 2.7467622203403153e-05,
       9.903113095788285e-05},
      {5.458863961393945e-05, 0.0012161185732111335, 1.3942229998065159e-05, 0.000692945730406791, 3.0649855034425855e-05,
       0.00010184079292230308},
      {0.00015268661081790924, 0.0013633521739393473, 0.00029863871168345213, 0.000867809634655714, 4.44393626821693e-05,
       0.0001869510015239939},
      {0.0004235670203343034, 0.0021772831678390503, 0.000502259295899421, 0.0024050779175013304, 0.00037864179466851056,
       0.0011415159096941352},
      {0.0004335033881943673, 0.003794487100094557, 0.0006943496991880238, 0.0039133052341639996, 0.0004368529189378023,
       0.0013122950913384557},
      {0.000433129578595981, 0.0038726271595805883, 0.0007004002691246569, 0.003933240193873644, 0.0006498713628388941,
       0.0013534179888665676},
      {0.0009417368564754725, 0.004829882178455591, 0.0007001066696830094, 0.004029807168990374, 0.0010588964214548469,
       0.00332801416516304},
      {0.0010664216242730618, 0.004825052805244923, 0.0009519456652924418, 0.004039266612380743, 0.0016515799798071384,
       0.0033250616397708654},
      {0.0010698811383917928, 0.005328051745891571, 0.0012366907903924584, 0.004053883254528046, 0.001727819093503058,
       0.004129813984036446},
  };

  ASSERT_TRUE(weights_per_step.size() == total_step + 1);
  ASSERT_TRUE(gradients_per_step.size() == total_step);
  ASSERT_TRUE(momentums_1_per_step.size() == total_step + 1);
  ASSERT_TRUE(momentums_2_per_step.size() == total_step + 1);

  for (size_t step = 0; step < total_step; ++step) {
    OpTester test("Adam", 1, onnxruntime::kMSDomain);
    std::vector<TensorInfo> weight_tensor_infos{TensorInfo({2, 3}, weights_per_step[step])};
    std::vector<TensorInfo> gradient_tensor_infos{TensorInfo({2, 3}, gradients_per_step[step])};
    std::vector<TensorInfo> momentum_1_tensor_infos{TensorInfo({2, 3}, momentums_1_per_step[step])};
    std::vector<TensorInfo> momentum_2_tensor_infos{TensorInfo({2, 3}, momentums_2_per_step[step])};

    std::vector<TensorInfo> updated_weight_tensor_infos{TensorInfo({2, 3}, weights_per_step[step + 1])};
    std::vector<TensorInfo> updated_momentum_1_tensor_infos{TensorInfo({2, 3}, momentums_1_per_step[step + 1])};
    std::vector<TensorInfo> updated_momentum_2_tensor_infos{TensorInfo({2, 3}, momentums_2_per_step[step + 1])};
    AdamTestInputOutput<float> data(lr, step,
                                    weight_tensor_infos, gradient_tensor_infos,
                                    momentum_1_tensor_infos, momentum_2_tensor_infos,
                                    updated_weight_tensor_infos, updated_momentum_1_tensor_infos,
                                    updated_momentum_2_tensor_infos);

    // Default values for Torch AdamW.
    test.AddAttribute("alpha", static_cast<float>(0.9f));
    test.AddAttribute("beta", static_cast<float>(0.999f));
    test.AddAttribute("epsilon", static_cast<float>(1e-8f));
    test.AddAttribute("weight_decay", static_cast<float>(1e-2f));
    test.AddAttribute("adam_mode", static_cast<int64_t>(0));
    test.AddAttribute("correct_bias", static_cast<int64_t>(1));

    // Add test inputs.
    test.AddSeqInput("weights", data.WeightSeq());
    test.AddSeqInput("gradients", data.GradientSeq());
    test.AddSeqInput("momentums_1", data.Momentum_1_Seq());
    test.AddSeqInput("momentums_2", data.Momentum_2_Seq());
    test.AddInput<float>("lr", {1}, data.lr_vector);
    test.AddInput<int64_t>("step", {1}, data.step_vector);

    // Add test outputs as baseline.
    float param_rtol = 1e-5f;
    float param_atol = 1e-4f;
    test.AddOutput<int64_t>("updated_flag", {1}, {1});
    test.AddSeqOutput("updated_weights", data.UpdatedWeightSeq(), param_rtol, param_atol);

    float momentum1_rtol = 1e-3f;
    float momentum1_atol = 1e-6f;
    test.AddSeqOutput("updated_momentums_1", data.UpdatedMomentum_1_Seq(), momentum1_rtol, momentum1_atol);

    float momentum2_rtol = 1e-3f;
    float momentum2_atol = 1e-7f;
    test.AddSeqOutput("updated_momentums_2", data.UpdatedMomentum_2_Seq(), momentum2_rtol, momentum2_atol);

    test.Run();
  }
}

TEST(AdamTest, TorchAdamMultipleWeightsTest_Loop10Steps) {
  size_t total_step = 10;
  float lr = 1e-03;

  // 11 steps of weight values before applying optimization.
  std::unordered_map<std::string, std::vector<std::vector<float>>> named_weights_per_step{
      {
          "fc1.weight",
          {
              {-0.18330414593219757, 0.6739549040794373, 0.31170889735221863, 0.42830976843833923, -0.3957911729812622,
               0.07424858212471008},
              {-0.1823023110628128, 0.6729481816291809, 0.31270575523376465, 0.4273054897785187, -0.3947872221469879,
               0.07324783504009247},
              {-0.1813177615404129, 0.6725299954414368, 0.31352442502975464, 0.4267500042915344, -0.39517560601234436,
               0.07235248386859894},
              {-0.18059654533863068, 0.6721751093864441, 0.3133564889431, 0.4261542558670044, -0.3952518701553345,
               0.07177812606096268},
              {-0.1797766387462616, 0.6717073917388916, 0.31389161944389343, 0.42545586824417114, -0.3956265449523926,
               0.0718231126666069},
              {-0.1797962337732315, 0.671058714389801, 0.31389155983924866, 0.42466312646865845, -0.3952196538448334,
               0.07233689725399017},
              {-0.179893359541893, 0.6702919602394104, 0.3141656517982483, 0.4244508147239685, -0.3947013318538666,
               0.07293851673603058},
              {-0.17997200787067413, 0.6695550084114075, 0.3144531548023224, 0.42422598600387573, -0.3940390944480896,
               0.07336583733558655},
              {-0.17965379357337952, 0.6687510013580322, 0.3146941661834717, 0.4239514470100403, -0.39327237010002136,
               0.07322362810373306},
              {-0.17922040820121765, 0.6680363416671753, 0.31512853503227234, 0.4236794114112854, -0.3924334645271301,
               0.07309211790561676},
              {-0.17886576056480408, 0.6672791242599487, 0.3152349591255188, 0.42340385913848877, -0.39180418848991394,
               0.07277242839336395},
          },
      },
      {
          "fc1.bias",
          {
              {0.517955482006073, -0.435107946395874, -0.12118204683065414},
              {0.5169503092765808, -0.4351035952568054, -0.12218083441257477},
              {0.5160060524940491, -0.43435510993003845, -0.12318029999732971},
              {0.5150943994522095, -0.4335651397705078, -0.12397350370883942},
              {0.5141466856002808, -0.4329172670841217, -0.12462301552295685},
              {0.5137341618537903, -0.43236902356147766, -0.12517181038856506},
              {0.5133119821548462, -0.4326229393482208, -0.1256912797689438},
              {0.5132887363433838, -0.4328441321849823, -0.1262883096933365},
              {0.513144850730896, -0.4324527084827423, -0.1269497573375702},
              {0.5130518078804016, -0.4321047365665436, -0.127536803483963},
              {0.5128913521766663, -0.4317937195301056, -0.12806057929992676},
          },
      },
      {
          "fc2.weight",
          {
              {-0.5107945203781128, 0.04572092741727829, 0.21493154764175415, -0.03950735926628113,
               -0.3590133488178253, 0.30300942063331604},
              {-0.5097894072532654, 0.04572046920657158, 0.21592940390110016, -0.040506962686777115,
               -0.3590097427368164, 0.30200639367103577},
              {-0.5088188052177429, 0.04646414518356323, 0.21664850413799286, -0.04150328040122986,
               -0.35975027084350586, 0.30123963952064514},
              {-0.5078955888748169, 0.047161854803562164, 0.2173282355070114, -0.042312245815992355,
               -0.3605462908744812, 0.30057719349861145},
              {-0.5069411396980286, 0.047733284533023834, 0.21788464486598969, -0.04310775548219681,
               -0.36119768023490906, 0.3000340163707733},
              {-0.506521463394165, 0.04821619391441345, 0.21835459768772125, -0.043949466198682785,
               -0.36174771189689636, 0.29957443475723267},
              {-0.5059956312179565, 0.047795072197914124, 0.21833021938800812, -0.044635750353336334,
               -0.3613414764404297, 0.29929450154304504},
              {-0.5057910680770874, 0.04742725193500519, 0.21826116740703583, -0.04537033289670944,
               -0.36098626255989075, 0.2990230321884155},
              {-0.5054700970649719, 0.047109540551900864, 0.21849225461483002, -0.04618074744939804,
               -0.36095497012138367, 0.2985096275806427},
              {-0.5052005648612976, 0.046827442944049835, 0.21869714558124542, -0.04699970409274101,
               -0.3609268069267273, 0.298053503036499},
              {-0.5048867464065552, 0.0465756319463253, 0.21887977421283722, -0.047773923724889755,
               -0.36090126633644104, 0.29764610528945923},
          },
      },
      {
          "fc2.bias",
          {
              {0.023823332041502, 0.5375885367393494},
              {0.02482309378683567, 0.5365831851959229},
              {0.025780897587537766, 0.5355805158615112},
              {0.0266813226044178, 0.5347577333450317},
              {0.027619561180472374, 0.5339611172676086},
              {0.02818547561764717, 0.533092737197876},
              {0.028722008690238, 0.5324080586433411},
              {0.028895270079374313, 0.5316585302352905},
              {0.0292242132127285, 0.5308324694633484},
              {0.02950773946940899, 0.5300171375274658},
              {0.0298329945653677, 0.529287576675415},
          },
      },
  };

  // 10 steps of gradient values used to apply optimization.
  std::unordered_map<std::string, std::vector<std::vector<float>>> named_gradients_per_step{
      {
          "fc1.weight",
          {
              {-0.09586180746555328, 0.17629344761371613, 0.0, 0.0, -0.32529348134994507, 0.04030714929103851},
              {0.06833842396736145, 0.08454680442810059, -0.03257494419813156, 0.0038211802020668983,
               0.1191219612956047, 0.22664979100227356},
              {0.14586228132247925, 0.06190881133079529, -0.0484643280506134, -0.08001512289047241,
               0.010100812651216984, 0.019007522612810135},
              {-0.137947678565979, -0.046707138419151306, 0.0, 0.0, 0.0, 0.0},
              {0.17390619218349457, 0.5486620664596558, 0.0, 0.0, 0.0, 0.0},
              {-0.5882855653762817, -0.7570041418075562, 0.1739857792854309, 0.22667543590068817, 0.052081093192100525,
               0.06785327196121216},
              {0.163396418094635, -0.05490700528025627, 0.0, 0.0, -0.07044854760169983, 0.04285266995429993},
              {-0.04709528759121895, 0.18947599828243256, -0.5040349960327148, 0.18439726531505585,
               -0.01673167198896408, 0.17345011234283447},
              {-0.0806330144405365, 0.07000920176506042, 0.0, 0.0, 0.0, 0.0},
              {0.022376326844096184, 0.0734390839934349, 0.0, 0.0, 0.0, 0.0},
          },
      },
      {
          "fc1.bias",
          {
              {0.309002548456192, 0.0, 0.3643433749675751},
              {0.16205920279026031, -0.02531510405242443, 0.3757982850074768},
              {0.13360804319381714, -0.07762981206178665, 0.017482705414295197},
              {0.30951613187789917, 0.0, 0.0},
              {-0.2870372533798218, 0.0, 0.0},
              {0.07509520649909973, 0.1636124551296234, 0.048975929617881775},
              {-0.3837743401527405, 0.0, 0.18683575093746185},
              {0.175801083445549, -0.45883896946907043, 0.19719897210597992},
              {-0.05067116767168045, 0.0, 0.0},
              {0.11543156206607819, 0.0, 0.0},
          },
      },
      {
          "fc2.weight",
          {
              {-0.31826627254486084, 0.0, -0.1022794172167778, 0.7872374057769775, 0.0, 0.2039588987827301},
              {-0.2035769671201706, -0.012987848371267319, -0.007285610307008028, 0.7206295132637024,
               0.021516945213079453, 0.02756710723042488},
              {-0.13538049161434174, -0.11737341433763504, -0.022564847022294998, 0.06767335534095764,
               0.05762113258242607, 0.023621685802936554},
              {-0.34123802185058594, 0.0, 0.0, 0.30149734020233154, 0.0, 0.0},
              {0.3098701536655426, 0.0, 0.0, 1.4480323791503906, 0.0, 0.0},
              {-0.2343340367078781, 0.5370868444442749, 0.08742398768663406, -0.13039062917232513,
               -0.26853200793266296, -0.0437101349234581},
              {0.30305129289627075, 0.0, 0.012864593416452408, 0.6519851684570312, 0.0, 0.01125416811555624},
              {-0.22530147433280945, -0.007280223537236452, -0.0945650264620781, 1.1682872772216797,
               0.15443314611911774, 0.19558396935462952},
              {0.024412253871560097, 0.0, 0.0, 0.5862233638763428, 0.0, 0.0},
              {-0.11912607401609421, 0.0, 0.0, 0.22673514485359192, 0.0, 0.0},
          },
      },
      {
          "fc2.bias",
          {
              {-0.7384594678878784, 1.726222276687622},
              {-0.44500619173049927, 1.5997315645217896},
              {-0.2772650718688965, 0.1799774169921875},
              {-0.6588927507400513, 0.5939797759056091},
              {0.39522403478622437, 2.0108203887939453},
              {-0.11679565906524658, -0.3625909686088562},
              {0.6392423510551453, 1.3513944149017334},
              {-0.5523114204406738, 2.2823963165283203},
              {0.02510213851928711, 0.8224809169769287},
              {-0.2295447289943695, 0.01137387752532959},
          },
      },
  };

  // 11 steps of momentum1 values before applying optimization.
  std::unordered_map<std::string, std::vector<std::vector<float>>>
      named_momentums_1_per_step{
          {
              "fc1.weight",
              {
                  {0.0, 0.0, 0.0, 0.0, 0.0, 0.0},
                  {-0.009586180560290813, 0.017629345878958702, 0.0, 0.0, -0.032529350370168686, 0.004030715208500624},
                  {-0.0017937193624675274, 0.024321090430021286, -0.003257494419813156, 0.00038211801438592374,
                   -0.017364216968417168, 0.026292623952031136},
                  {0.012971880845725536, 0.028079861775040627, -0.0077781775034964085, -0.007657606154680252,
                   -0.01461771223694086, 0.02556411363184452},
                  {-0.0021200752817094326, 0.020601162686944008, -0.007000359706580639, -0.0068918452598154545,
                   -0.013155940920114517, 0.023007702082395554},
                  {0.015482551418244839, 0.07340725511312485, -0.0063003236427903175, -0.006202660501003265,
                   -0.01184034626930952, 0.02070693112909794},
                  {-0.0448942631483078, -0.00963388942182064, 0.011728287674486637, 0.017085149884223938,
                   -0.005448201671242714, 0.025421565398573875},
                  {-0.02406519465148449, -0.014161201193928719, 0.010555458255112171, 0.015376634895801544,
                   -0.011948236264288425, 0.027164675295352936},
                  {-0.02636820264160633, 0.006202519405633211, -0.04090358689427376, 0.032278697937726974,
                   -0.012426580302417278, 0.04179321974515915},
                  {-0.03179468587040901, 0.012583187781274319, -0.03681322559714317, 0.029050827026367188,
                   -0.011183922179043293, 0.037613898515701294},
                  {-0.026377582922577858, 0.018668776378035545, -0.03313190117478371, 0.02614574320614338,
                   -0.010065529495477676, 0.033852506428956985},
              },
          },
          {
              "fc1.bias",
              {
                  {0.0, 0.0, 0.0},
                  {0.0309002548456192, 0.0, 0.03643433749675751},
                  {0.04401614889502525, -0.0025315105449408293, 0.07037073373794556},
                  {0.05297533795237541, -0.010041340254247189, 0.06508193165063858},
                  {0.07862941920757294, -0.009037205949425697, 0.05857373774051666},
                  {0.042062751948833466, -0.008133484981954098, 0.05271636322140694},
                  {0.04536599665880203, 0.00904110912233591, 0.05234232172369957},
                  {0.0024519632570445538, 0.008136997930705547, 0.06579166650772095},
                  {0.019786875694990158, -0.03856059908866882, 0.07893239706754684},
                  {0.012741071172058582, -0.03470453992486, 0.07103915512561798},
                  {0.023010119795799255, -0.03123408555984497, 0.06393523514270782},
              },
          },
          {
              "fc2.weight",
              {
                  {0.0, 0.0, 0.0, 0.0, 0.0, 0.0},
                  {-0.031826626509428024, 0.0, -0.010227941907942295, 0.07872374355792999, 0.0, 0.02039588987827301},
                  {-0.04900166019797325, -0.0012987848604097962, -0.009933708235621452, 0.1429143249988556,
                   0.0021516946144402027, 0.021113011986017227},
                  {-0.05763953924179077, -0.01290624774992466, -0.011196821928024292, 0.13539022207260132,
                   0.007698638364672661, 0.02136388048529625},
                  {-0.08599938452243805, -0.011615622788667679, -0.010077139362692833, 0.15200093388557434,
                   0.006928774528205395, 0.019227491691708565},
                  {-0.046412430703639984, -0.010454060509800911, -0.00906942505389452, 0.2816040813922882,
                   0.006235897075384855, 0.017304742708802223},
                  {-0.06520459055900574, 0.044300030916929245, 0.0005799162317998707, 0.24040459096431732,
                   -0.021240893751382828, 0.011203254573047161},
                  {-0.02837899886071682, 0.03987002745270729, 0.0018083839677274227, 0.2815626561641693,
                   -0.019116804003715515, 0.01120834518224001},
                  {-0.0480712465941906, 0.035155002027750015, -0.00782895740121603, 0.3702351152896881,
                   -0.0017618080601096153, 0.029645908623933792},
                  {-0.04082289710640907, 0.031639501452445984, -0.00704606156796217, 0.39183393120765686,
                   -0.001585627207532525, 0.026681317016482353},
                  {-0.04865321144461632, 0.028475550934672356, -0.006341455038636923, 0.3753240406513214,
                   -0.0014270644169300795, 0.024013184010982513},
              },
          },
          {
              "fc2.bias",
              {
                  {0.0, 0.0},
                  {-0.07384594529867172, 0.17262223362922668},
                  {-0.11096196621656418, 0.31533315777778625},
                  {-0.1275922656059265, 0.3017975687980652},
                  {-0.18072231113910675, 0.33101576566696167},
                  {-0.12312767654657364, 0.49899622797966003},
                  {-0.12249447405338287, 0.41283750534057617},
                  {-0.04632079228758812, 0.5066931843757629},
                  {-0.09691985696554184, 0.6842634677886963},
                  {-0.08471765369176865, 0.6980851888656616},
                  {-0.09920036047697067, 0.6294140219688416},
              },
          },
      };

  // 11 steps of momentum2 values before applying optimization.
  std::unordered_map<std::string, std::vector<std::vector<float>>>
      named_momentums_2_per_step{
          {
              "fc1.weight",
              {
                  {0.0, 0.0, 0.0, 0.0, 0.0, 0.0},
                  {9.189487172989175e-06, 3.107938027824275e-05, 0.0, 0.0, 0.00010581585229374468,
                   1.6246663108177017e-06},
                  {1.3850438335794024e-05, 3.8196463719941676e-05, 1.0611270226945635e-06, 1.4601418740767258e-08,
                   0.00011990008351858705, 5.2993171266280115e-05},
                  {3.5112392652081326e-05, 4.199097020318732e-05, 3.4088570828316733e-06, 6.417007170966826e-06,
                   0.000119882206490729, 5.3301468142308295e-05},
                  {5.410684389062226e-05, 4.4130538299214095e-05, 3.4054482966894284e-06, 6.4105902310984675e-06,
                   0.00011976232781307772, 5.3248168114805594e-05},
                  {8.429610170423985e-05, 0.0003451164811849594, 3.402042921152315e-06, 6.404179657693021e-06,
                   0.00011964256555074826, 5.319491901900619e-05},
                  {0.00043029175139963627, 0.0009178266627714038, 3.3669693948468193e-05, 5.7779529015533626e-05,
                   0.00012223536032252014, 5.774579040007666e-05},
                  {0.0004565598501358181, 0.0009199236519634724, 3.363602445460856e-05, 5.7721750636119395e-05,
                   0.0001270761276828125, 5.952439460088499e-05},
                  {0.00045832127216272056, 0.0009549048845656216, 0.0002876536746043712, 9.166638483293355e-05,
                   0.00012722901010420173, 8.95498160389252e-05},
                  {0.0004643646243494004, 0.0009588512475602329, 0.00028736601234413683, 9.157472231891006e-05,
                   0.00012710178270936012, 8.946027082856745e-05},
                  {0.00046440097503364086, 0.0009632856817916036, 0.00028707864112220705, 9.148314711637795e-05,
                   0.00012697468628175557, 8.937081292970106e-05},
              },
          },
          {
              "fc1.bias",
              {
                  {0.0, 0.0, 0.0},
                  {9.548258094582707e-05, 0.0, 0.00013274610682856292},
                  {0.00012165028601884842, 6.408545232261531e-07, 0.0002738377370405942},
                  {0.00013937974290456623, 6.666601620963775e-06, 0.00027386954752728343},
                  {0.00023504059936385602, 6.659935024799779e-06, 0.00027359568048268557},
                  {0.0003171959542669356, 6.653275249846047e-06, 0.0002733220753725618},
                  {0.00032251805532723665, 3.3415657526347786e-05, 0.00027544741169549525},
                  {0.0004694783128798008, 3.338224269100465e-05, 0.00031007957295514643},
                  {0.0004999148659408092, 0.00024388206657022238, 0.0003486569330561906},
                  {0.0005019825184717774, 0.00024363819102291018, 0.00034830826916731894},
                  {0.0005148049676790833, 0.00024339456285815686, 0.00034795995452441275},
              },
          },
          {
              "fc2.weight",
              {
                  {0.0, 0.0, 0.0, 0.0, 0.0, 0.0},
                  {0.00010129342990694568, 0.0, 1.0461079000378959e-05, 0.0006197427865117788, 0.0,
                   4.159923628321849e-05},
                  {0.00014263571938499808, 1.6868420971150044e-07, 1.0503697922104038e-05, 0.0011384299723431468,
                   4.6297896005853545e-07, 4.2317580664530396e-05},
                  {0.00016082095680758357, 1.3945034879725426e-05, 1.100236659112852e-05, 0.001141871209256351,
                   3.782711246458348e-06, 4.283324597054161e-05},
                  {0.0002771035360638052, 1.3931089597463142e-05, 1.0991364433721174e-05, 0.0012316300999373198,
                   3.7789286579936743e-06, 4.2790412408066913e-05},
                  {0.00037284597055986524, 1.3917158867116086e-05, 1.0980373190250248e-05, 0.003327196231111884,
                   3.7751497075078078e-06, 4.27476225013379e-05},
                  {0.00042738555930554867, 0.00030236554448492825, 1.8612347048474476e-05, 0.003340870840474963,
                   7.588081643916667e-05, 4.4615451770368963e-05},
                  {0.0005187982460483909, 0.00030206318479031324, 1.8759232261800207e-05, 0.003762614680454135,
                   7.580493547720835e-05, 4.469749183044769e-05},
                  {0.0005690401885658503, 0.0003018141142092645, 2.7683017833624035e-05, 0.0051237475126981735,
                   9.957873407984152e-05, 8.290588448289782e-05},
                  {0.0005690670805051923, 0.0003015123074874282, 2.765533463389147e-05, 0.005462281871587038,
                   9.947915532393381e-05, 8.282298222184181e-05},
                  {0.0005826890701428056, 0.00030121079180389643, 2.7627680537989363e-05, 0.005508228670805693,
                   9.93796784314327e-05, 8.274015999631956e-05},
              },
          },
          {
              "fc2.bias",
              {
                  {0.0, 0.0},
                  {0.0005453223711811006, 0.0029798434115946293},
                  {0.0007428076351061463, 0.005536004900932312},
                  {0.0008189407526515424, 0.005562860984355211},
                  {0.0012522615725174546, 0.00591011019423604},
                  {0.0014072112971916795, 0.009947598911821842},
                  {0.0014194452669471502, 0.010069123469293118},
                  {0.0018266566330567002, 0.011885321699082851},
                  {0.002129877917468548, 0.01708276942372322},
                  {0.0021283780224621296, 0.017742162570357323},
                  {0.0021789404563605785, 0.017724549397826195},
              },
          },
      };

  ASSERT_TRUE(named_weights_per_step.size() == 4);
  ASSERT_TRUE(named_gradients_per_step.size() == 4);
  ASSERT_TRUE(named_momentums_1_per_step.size() == 4);
  ASSERT_TRUE(named_momentums_2_per_step.size() == 4);

  ASSERT_TRUE(named_weights_per_step["fc1.weight"].size() == total_step + 1);
  ASSERT_TRUE(named_gradients_per_step["fc1.weight"].size() == total_step);
  ASSERT_TRUE(named_momentums_1_per_step["fc1.weight"].size() == total_step + 1);
  ASSERT_TRUE(named_momentums_2_per_step["fc1.weight"].size() == total_step + 1);

  for (size_t step = 0; step < total_step; ++step) {
    OpTester test("Adam", 1, onnxruntime::kMSDomain);

    // Weights/momentums before applying optimization.
    std::vector<TensorInfo> weight_tensor_infos{
        TensorInfo({2, 3}, named_weights_per_step["fc1.weight"][step]),
        // TensorInfo({3}, named_weights_per_step["fc1.bias"][step]),
        // TensorInfo({3, 2}, named_weights_per_step["fc2.weight"][step]),
        // TensorInfo({2}, named_weights_per_step["fc2.bias"][step]),
    };

    std::vector<TensorInfo> gradient_tensor_infos{
        TensorInfo({2, 3}, named_gradients_per_step["fc1.weight"][step]),
        // TensorInfo({3}, named_gradients_per_step["fc1.bias"][step]),
        // TensorInfo({3, 2}, named_gradients_per_step["fc2.weight"][step]),
        // TensorInfo({2}, named_gradients_per_step["fc2.bias"][step]),
    };

    std::vector<TensorInfo> momentum_1_tensor_infos{
        TensorInfo({2, 3}, named_momentums_1_per_step["fc1.weight"][step]),
        // TensorInfo({3}, named_momentums_1_per_step["fc1.bias"][step]),
        // TensorInfo({3, 2}, named_momentums_1_per_step["fc2.weight"][step]),
        // TensorInfo({2}, named_momentums_1_per_step["fc2.bias"][step]),
    };

    std::vector<TensorInfo> momentum_2_tensor_infos{
        TensorInfo({2, 3}, named_momentums_2_per_step["fc1.weight"][step]),
        // TensorInfo({3}, named_momentums_2_per_step["fc1.bias"][step]),
        // TensorInfo({3, 2}, named_momentums_2_per_step["fc2.weight"][step]),
        // TensorInfo({2}, named_momentums_2_per_step["fc2.bias"][step]),
    };

    // Updated weights/momentums values for validation.
    std::vector<TensorInfo> updated_weight_tensor_infos{
        TensorInfo({2, 3}, named_weights_per_step["fc1.weight"][step + 1]),
        // TensorInfo({3}, named_weights_per_step["fc1.bias"][step + 1]),
        // TensorInfo({3, 2}, named_weights_per_step["fc2.weight"][step + 1]),
        // TensorInfo({2}, named_weights_per_step["fc2.bias"][step + 1]),
    };

    std::vector<TensorInfo> updated_momentum_1_tensor_infos{
        TensorInfo({2, 3}, named_momentums_1_per_step["fc1.weight"][step + 1]),
        // TensorInfo({3}, named_momentums_1_per_step["fc1.bias"][step + 1]),
        // TensorInfo({3, 2}, named_momentums_1_per_step["fc2.weight"][step + 1]),
        // TensorInfo({2}, named_momentums_1_per_step["fc2.bias"][step + 1]),
    };

    std::vector<TensorInfo> updated_momentum_2_tensor_infos{
        TensorInfo({2, 3}, named_momentums_2_per_step["fc1.weight"][step + 1]),
        // TensorInfo({3}, named_momentums_2_per_step["fc1.bias"][step + 1]),
        // TensorInfo({3, 2}, named_momentums_2_per_step["fc2.weight"][step + 1]),
        // TensorInfo({2}, named_momentums_2_per_step["fc2.bias"][step + 1]),
    };

    AdamTestInputOutput<float> data(lr, step,
                                    weight_tensor_infos, gradient_tensor_infos,
                                    momentum_1_tensor_infos, momentum_2_tensor_infos,
                                    updated_weight_tensor_infos, updated_momentum_1_tensor_infos,
                                    updated_momentum_2_tensor_infos);

    // Default values for Torch AdamW.
    test.AddAttribute("alpha", static_cast<float>(0.9f));
    test.AddAttribute("beta", static_cast<float>(0.999f));
    test.AddAttribute("epsilon", static_cast<float>(1e-8f));
    test.AddAttribute("weight_decay", static_cast<float>(1e-2f));
    test.AddAttribute("adam_mode", static_cast<int64_t>(0));
    test.AddAttribute("correct_bias", static_cast<int64_t>(1));

    // Add test inputs.
    test.AddSeqInput("weights", data.WeightSeq());
    test.AddSeqInput("gradients", data.GradientSeq());
    test.AddSeqInput("momentums_1", data.Momentum_1_Seq());
    test.AddSeqInput("momentums_2", data.Momentum_2_Seq());
    test.AddInput<float>("lr", {1}, data.lr_vector);
    test.AddInput<int64_t>("step", {1}, data.step_vector);

    // Add test outputs as baseline.
    float param_rtol = 1e-5f;
    float param_atol = 1e-4f;
    test.AddOutput<int64_t>("updated_flag", {1}, {1});
    test.AddSeqOutput("updated_weights", data.UpdatedWeightSeq(), param_rtol, param_atol);

    float momentum1_rtol = 1e-3f;
    float momentum1_atol = 1e-6f;
    test.AddSeqOutput("updated_momentums_1", data.UpdatedMomentum_1_Seq(), momentum1_rtol, momentum1_atol);

    float momentum2_rtol = 1e-3f;
    float momentum2_atol = 1e-7f;
    test.AddSeqOutput("updated_momentums_2", data.UpdatedMomentum_2_Seq(), momentum2_rtol, momentum2_atol);

    test.Run();
  }
}
// TODO: adding more test cases.

}  // namespace
}  // namespace test
}  // namespace onnxruntime
